import streamlit as st
import feedparser
import pandas as pd
from deep_translator import GoogleTranslator
from datetime import datetime
import re

def clean_html(text):
    """HTML íƒœê·¸ ì œê±°"""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def translate_text(text):
    """í…ìŠ¤íŠ¸ ë²ˆì—­ í•¨ìˆ˜"""
    try:
        # ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬
        if not text or text.isspace():
            return ""
            
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš° ë‚˜ëˆ ì„œ ë²ˆì—­
        max_length = 4500  # Google ë²ˆì—­ ì œí•œ
        if len(text) > max_length:
            parts = [text[i:i+max_length] for i in range(0, len(text), max_length)]
            translated_parts = []
            for part in parts:
                if part and not part.isspace():
                    translated = GoogleTranslator(source='en', target='ko').translate(text=part)
                    translated_parts.append(translated)
            return ' '.join(translated_parts)
        else:
            if text and not text.isspace():
                return GoogleTranslator(source='en', target='ko').translate(text=text)
            return ""
    except Exception as e:
        st.error(f"ë²ˆì—­ ì˜¤ë¥˜: {str(e)}")
        return f"ë²ˆì—­ ì‹¤íŒ¨: {text[:100]}..."

def format_date(date_str):
    """ë‚ ì§œ í˜•ì‹ ë³€í™˜"""
    try:
        return datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %z').strftime('%Y-%m-%d %H:%M')
    except:
        return date_str

def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="TechCrunch ë‰´ìŠ¤ ë²ˆì—­ê¸°",
        page_icon="ğŸŒ",
        layout="wide"
    )
    
    # ì œëª©ê³¼ ì„¤ëª…
    st.title("ğŸŒ TechCrunch ë‰´ìŠ¤ ë²ˆì—­ê¸°")
    st.markdown("TechCrunchì˜ ìµœì‹  ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.")
    
    # TechCrunch RSS í”¼ë“œ URL
    techcrunch_feed = "https://techcrunch.com/feed/"
    
    try:
        with st.spinner('ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë²ˆì—­í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            # RSS í”¼ë“œ íŒŒì‹±
            feed = feedparser.parse(techcrunch_feed)
            
            # ë°ì´í„° ì¶”ì¶œ ë° ë²ˆì—­
            feed_data = []
            
            # ì§„í–‰ ìƒíƒœ í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, entry in enumerate(feed.entries[:10]):
                status_text.text(f'{i+1}/10 ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...')
                
                # ì œëª© ë²ˆì—­
                title = clean_html(entry.title)
                translated_title = translate_text(title)
                
                # ìš”ì•½ ë²ˆì—­
                description = clean_html(entry.get('description', ''))
                translated_description = translate_text(description) if description else ''
                
                # ë‚ ì§œ ì²˜ë¦¬
                published = entry.get('published', entry.get('updated', 'No date'))
                formatted_date = format_date(published)
                
                feed_data.append({
                    'ì›ë¬¸ ì œëª©': title,
                    'ë²ˆì—­ ì œëª©': translated_title,
                    'ë‚ ì§œ': formatted_date,
                    'ì›ë¬¸ ë‚´ìš©': description,
                    'ë²ˆì—­ ë‚´ìš©': translated_description,
                    'ë§í¬': entry.link
                })
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_bar.progress((i + 1) / 10)
            
            # ì§„í–‰ ìƒíƒœ í‘œì‹œ ì œê±°
            progress_bar.empty()
            status_text.empty()
            
            # ë‰´ìŠ¤ í‘œì‹œ
            st.markdown("### ğŸ“° ìµœì‹  ë‰´ìŠ¤")
            
            # ê° ë‰´ìŠ¤ í•­ëª©ì„ expanderë¡œ í‘œì‹œ
            for idx, item in enumerate(feed_data, 1):
                with st.expander(f"#{idx}. {item['ë²ˆì—­ ì œëª©']}", expanded=False):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ğŸ“ ì›ë¬¸")
                        st.subheader(item['ì›ë¬¸ ì œëª©'])
                        st.write(item['ì›ë¬¸ ë‚´ìš©'])
                    
                    with col2:
                        st.subheader("ğŸ”„ ë²ˆì—­")
                        st.subheader(item['ë²ˆì—­ ì œëª©'])
                        st.write(item['ë²ˆì—­ ë‚´ìš©'])
                    
                    st.write(f"ğŸ“… ê²Œì‹œì¼: {item['ë‚ ì§œ']}")
                    st.markdown(f"ğŸ”— [ê¸°ì‚¬ ë§í¬]({item['ë§í¬']})")
            
            # CSV ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            st.markdown("### ğŸ’¾ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
            df = pd.DataFrame(feed_data)
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ë²ˆì—­ ê²°ê³¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="techcrunch_translated_news.csv",
                mime="text/csv"
            )
            
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.markdown("ìƒˆë¡œê³ ì¹¨ì„ í•´ë³´ì‹œê±°ë‚˜, ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == '__main__':
    main()
